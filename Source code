# Install dependencies
!pip install pandas scikit-learn gradio

# Upload the CSV
from google.colab import files
uploaded = files.upload()

# Load dataset
import pandas as pd

# Read uploaded dataset
df = pd.read_csv('Fake.csv')
print("Shape:", df.shape)
df.head()

# Select relevant columns and handle missing values
df = df[['title', 'text']].dropna()

# Combine title and text
df['content'] = df['title'] + " " + df['text']

# Add label (all fake news, label = 0)
df['label'] = 0

# Prepare features and labels
X = df['content']
y = df['label']

#from sklearn.linear_model import LogisticRegression #Logistic regression won't work for anomaly detection
from sklearn.svm import OneClassSVM #Using OneClassSVM for anomaly detection
from sklearn.metrics import accuracy_score, classification_report

# Train model
#model = LogisticRegression() #Commented out as LogisticRegression is no longer used
model = OneClassSVM(nu=0.1, kernel="rbf", gamma=0.1) #Creating OneClassSVM model
model.fit(X_train_tfidf) #Fitting the model

# Predict and evaluate
y_pred = model.predict(X_test_tfidf) #Predicting on test data
y_pred[y_pred == 1] = 0 #Changing predictions to 0 (normal) and -1 (anomaly) to 0 and 1 respectively
y_pred[y_pred == -1] = 1
print("Accuracy:", accuracy_score(y_test, y_pred))
print("\nClassification Report:\n", classification_report(y_test, y_pred))

import gradio as gr

# Prediction function
def predict_fake_news(title, text):
    combined = title + " " + text
    vect_input = vectorizer.transform([combined])
    pred = model.predict(vect_input)[0]
    return "ðŸŸ¥ FAKE News" if pred == 0 else "ðŸŸ© Real News"

# Create interface
title_input = gr.Textbox(label="News Title")
text_input = gr.Textbox(label="News Content", lines=6)
output = gr.Label(label="Prediction")

gr.Interface(
    fn=predict_fake_news,
    inputs=[title_input, text_input],
    outputs=output,
    title="ðŸ“° Fake News Detector",
    description="Enter a news title and content to predict whether it is fake."
).launch()
